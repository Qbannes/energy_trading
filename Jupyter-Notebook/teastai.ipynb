{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ce236d6",
   "metadata": {},
   "source": [
    "# Strommarktdaten Deutschland - SMARD.de Analyse\n",
    "\n",
    "Dieses Notebook:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89681255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1be0fe4",
   "metadata": {},
   "source": [
    "# Trading-Bot Backtest\n",
    "\n",
    "In dieser Zelle wird ein einfacher regelbasierter Trading-Bot implementiert und auf der Datei `strompreise_deutschland_20251023_121022.csv` backgetestet.\n",
    "\n",
    "- Startkapital: 10.000 EUR\n",
    "- Strategie (Beispiel): Mean-Reversion mit Z-Score Ein-/Ausstiegen\n",
    "- Einheitengröße: 1 MWh pro Trade (fest)\n",
    "\n",
    "Die folgende Codezelle lädt die CSV, führt den Backtest aus und gibt Gewinn/Verlust sowie eine Equity-Visualisierung aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961eb3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Datei: strompreise_deutschland_20251023_121022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bedla\\AppData\\Local\\Temp\\ipykernel_41856\\2468340059.py:36: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['datetime'] = pd.to_datetime(df[first_col])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Konnte keine Datumsspalte in der CSV finden. Erstelle bitte eine Spalte `datetime` oder `timestamp`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDateParseError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfirst_col\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bedla\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1072\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m     values = \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m     result = arg._constructor(values, index=arg.index, name=arg.name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bedla\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:437\u001b[39m, in \u001b[36m_convert_listlike_datetimes\u001b[39m\u001b[34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[39m\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m result, tz_parsed = \u001b[43mobjects_to_datetime64\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[43m=\u001b[49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    447\u001b[39m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[32m    448\u001b[39m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bedla\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2415\u001b[39m, in \u001b[36mobjects_to_datetime64\u001b[39m\u001b[34m(data, dayfirst, yearfirst, utc, errors, allow_object, out_unit)\u001b[39m\n\u001b[32m   2413\u001b[39m data = np.asarray(data, dtype=np.object_)\n\u001b[32m-> \u001b[39m\u001b[32m2415\u001b[39m result, tz_parsed = \u001b[43mtslib\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2416\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2417\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2418\u001b[39m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2419\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2420\u001b[39m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[43m=\u001b[49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2421\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreso\u001b[49m\u001b[43m=\u001b[49m\u001b[43mabbrev_to_npy_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_unit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2422\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2425\u001b[39m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[32m   2426\u001b[39m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslib.pyx:412\u001b[39m, in \u001b[36mpandas._libs.tslib.array_to_datetime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslib.pyx:596\u001b[39m, in \u001b[36mpandas._libs.tslib.array_to_datetime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslib.pyx:553\u001b[39m, in \u001b[36mpandas._libs.tslib.array_to_datetime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/conversion.pyx:641\u001b[39m, in \u001b[36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/parsing.pyx:336\u001b[39m, in \u001b[36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/parsing.pyx:666\u001b[39m, in \u001b[36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mDateParseError\u001b[39m: Unknown datetime string format, unable to parse: 1538344800000;59.53;2018-09-30 22:00:00, at position 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m         df[\u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(df[first_col])\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mKonnte keine Datumsspalte in der CSV finden. Erstelle bitte eine Spalte `datetime` oder `timestamp`.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Werte-Spalte finden\u001b[39;00m\n\u001b[32m     41\u001b[39m value_col = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Konnte keine Datumsspalte in der CSV finden. Erstelle bitte eine Spalte `datetime` oder `timestamp`."
     ]
    }
   ],
   "source": [
    "# Backtest: Lade CSV, definiere einfachen Mean-Reversion-Bot und führe Simulation durch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import math\n",
    "\n",
    "# Datei suchen (relativ zum Workspace/Notebook)\n",
    "filename = 'strompreise_deutschland_20251023_121022.csv'\n",
    "files = list(Path('.').rglob(filename))\n",
    "if not files:\n",
    "    files = list(Path('..').rglob(filename))\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"Datei {filename} nicht gefunden. Bitte stelle sicher, dass sie im Workspace vorhanden ist.\")\n",
    "\n",
    "file_path = files[0]\n",
    "print(f\"Lade Datei: {file_path}\")\n",
    "\n",
    "# CSV lesen\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Versuche Datetime-Spalte zu finden / erzeugen\n",
    "if 'datetime' in df.columns:\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "elif 'timestamp' in df.columns:\n",
    "    # timestamp kann ms sein\n",
    "    try:\n",
    "        df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    except Exception:\n",
    "        df['datetime'] = pd.to_datetime(df['timestamp'])\n",
    "else:\n",
    "    # Heuristik: erste Spalte als datetime\n",
    "    first_col = df.columns[0]\n",
    "    try:\n",
    "        df['datetime'] = pd.to_datetime(df[first_col])\n",
    "    except Exception:\n",
    "        raise ValueError('Konnte keine Datumsspalte in der CSV finden. Erstelle bitte eine Spalte `datetime` oder `timestamp`.')\n",
    "\n",
    "# Werte-Spalte finden\n",
    "value_col = None\n",
    "for candidate in ['value', 'price', 'preis', 'wert']:\n",
    "    if candidate in df.columns:\n",
    "        value_col = candidate\n",
    "        break\n",
    "# Fallback: wenn nur 2 Spalten und eine ist datetime\n",
    "if value_col is None:\n",
    "    other_cols = [c for c in df.columns if c != 'datetime']\n",
    "    if len(other_cols) >= 1:\n",
    "        value_col = other_cols[0]\n",
    "    else:\n",
    "        raise ValueError('Konnte keine Werte-Spalte in der CSV finden.')\n",
    "\n",
    "# Bereinigen\n",
    "df = df[['datetime', value_col]].rename(columns={value_col: 'price'})\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "df = df.dropna(subset=['price']).sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "print(f\"Eingelesene Daten: {len(df)} Zeilen von {df['datetime'].min()} bis {df['datetime'].max()}\")\n",
    "\n",
    "# Backtest-Parameter\n",
    "START_CAPITAL = 10000.0\n",
    "UNIT_SIZE = 1.0  # MWh per trade\n",
    "ROLL_WINDOW = 96  # 1 Tag (24h * 4 Viertelstunden)\n",
    "Z_ENTRY = -1.0\n",
    "Z_EXIT = 1.0\n",
    "\n",
    "# Berechne Rolling-Statistiken\n",
    "df['rolling_mean'] = df['price'].rolling(window=ROLL_WINDOW, min_periods=20).mean()\n",
    "df['rolling_std'] = df['price'].rolling(window=ROLL_WINDOW, min_periods=20).std()\n",
    "df['zscore'] = (df['price'] - df['rolling_mean']) / df['rolling_std']\n",
    "\n",
    "# Simulation\n",
    "cash = START_CAPITAL\n",
    "position = 0.0\n",
    "entry_price = None\n",
    "trades = []\n",
    "equity_curve = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    price = row['price']\n",
    "    z = row['zscore']\n",
    "    time = row['datetime']\n",
    "\n",
    "    # equity mark-to-market\n",
    "    equity = cash + position * price\n",
    "    equity_curve.append({'datetime': time, 'equity': equity})\n",
    "\n",
    "    # Signals (nur handeln wenn Rolling-Stats vorhanden)\n",
    "    if not np.isfinite(z):\n",
    "        continue\n",
    "\n",
    "    # Entry: wenn stark unter dem Mittel (z <= Z_ENTRY) und keine Position\n",
    "    if z <= Z_ENTRY and position == 0:\n",
    "        # buy UNIT_SIZE\n",
    "        cost = UNIT_SIZE * price\n",
    "        if cash >= cost:\n",
    "            cash -= cost\n",
    "            position += UNIT_SIZE\n",
    "            entry_price = price\n",
    "            trades.append({'entry_time': time, 'entry_price': price, 'exit_time': None, 'exit_price': None, 'profit': None})\n",
    "    # Exit: wenn stark über dem Mittel (z >= Z_EXIT) und Position offen\n",
    "    elif z >= Z_EXIT and position > 0:\n",
    "        proceeds = UNIT_SIZE * price\n",
    "        cash += proceeds\n",
    "        # finalize last trade\n",
    "        if trades and trades[-1]['exit_time'] is None:\n",
    "            trades[-1]['exit_time'] = time\n",
    "            trades[-1]['exit_price'] = price\n",
    "            trades[-1]['profit'] = (price - trades[-1]['entry_price']) * UNIT_SIZE\n",
    "        position = 0.0\n",
    "        entry_price = None\n",
    "\n",
    "# Am Ende offene Positionen liquidieren\n",
    "if position > 0:\n",
    "    last_price = df['price'].iloc[-1]\n",
    "    cash += position * last_price\n",
    "    if trades and trades[-1]['exit_time'] is None:\n",
    "        trades[-1]['exit_time'] = df['datetime'].iloc[-1]\n",
    "        trades[-1]['exit_price'] = last_price\n",
    "        trades[-1]['profit'] = (last_price - trades[-1]['entry_price']) * UNIT_SIZE\n",
    "    position = 0.0\n",
    "\n",
    "final_equity = cash\n",
    "pnl = final_equity - START_CAPITAL\n",
    "return_pct = (pnl / START_CAPITAL) * 100\n",
    "\n",
    "trades_df = pd.DataFrame(trades)\n",
    "equity_df = pd.DataFrame(equity_curve)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print('\\nBacktest Ergebnis:')\n",
    "print(f'Startkapital: {START_CAPITAL:.2f} EUR')\n",
    "print(f'Endkapital: {final_equity:.2f} EUR')\n",
    "print(f'Gewinn / Verlust: {pnl:.2f} EUR ({return_pct:.2f} % )')\n",
    "print(f'Anzahl Trades: {len(trades_df)}')\n",
    "if not trades_df.empty:\n",
    "    wins = (trades_df['profit'] > 0).sum()\n",
    "    losses = (trades_df['profit'] <= 0).sum()\n",
    "    print(f'Gewonnene Trades: {wins}, Verlorene Trades: {losses}, Winrate: {wins / len(trades_df) * 100:.2f}%')\n",
    "\n",
    "# Equity-Plot\n",
    "fig = px.line(equity_df, x='datetime', y='equity', title='Equity Curve des Backtests')\n",
    "fig.update_yaxes(title='Equity (EUR)')\n",
    "fig.show()\n",
    "\n",
    "# Trade-Details anzeigen und speichern\n",
    "if not trades_df.empty:\n",
    "    display(trades_df.head(20))\n",
    "    trades_out = 'trades_backtest_strommarkt.csv'\n",
    "    trades_df.to_csv(trades_out, index=False)\n",
    "    print(f'Trades gespeichert in: {trades_out}')\n",
    "\n",
    "# Equity CSV speichern\n",
    "equity_out = 'equity_curve_backtest.csv'\n",
    "equity_df.to_csv(equity_out, index=False)\n",
    "print(f'Equity-Kurve gespeichert in: {equity_out}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea6d7ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Datei: strompreise_deutschland_20251023_121022.csv\n",
      "Eingelesene Daten: 247584 Zeilen von 2018-09-30 22:00:00 bis 2025-10-23 21:45:00\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mZeroDivisionError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 98\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# Entry long when z <= Z_ENTRY and no position\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m z <= Z_ENTRY \u001b[38;5;129;01mand\u001b[39;00m position == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     units = \u001b[43munits_from_risk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRISK_PER_TRADE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTRANSACTION_COST_PER_UNIT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m units < MIN_UNITS:\n\u001b[32m    100\u001b[39m         units = MIN_UNITS\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36munits_from_risk\u001b[39m\u001b[34m(equity, price, risk_per_trade, transaction_cost_per_unit)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munits_from_risk\u001b[39m(equity, price, risk_per_trade, transaction_cost_per_unit=\u001b[32m0.0\u001b[39m):\n\u001b[32m     78\u001b[39m     \u001b[38;5;66;03m# Vereinfacht: wir erlauben, dass die gesamte 'risk_per_trade' des Equity in Position investiert wird\u001b[39;00m\n\u001b[32m     79\u001b[39m     notional = equity * risk_per_trade\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     units = math.floor(\u001b[43mnotional\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mprice\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransaction_cost_per_unit\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mint\u001b[39m(units), \u001b[32m0\u001b[39m)\n",
      "\u001b[31mZeroDivisionError\u001b[39m: division by zero"
     ]
    }
   ],
   "source": [
    "# Trading-Bot (erweitert) — mehrere Strategien, Positionsgrößen und Performance-Kennzahlen\n",
    "# Lädt die angegebene CSV, führt den Backtest durch und speichert Ergebnisse.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import math\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Konfiguration ---\n",
    "CSV_FILENAME = 'strompreise_deutschland_20251023_121022.csv'\n",
    "START_CAPITAL = 10000.0\n",
    "RISK_PER_TRADE = 0.05        # Anteil des Kapitals, der pro Trade riskiert werden soll (z.B. 0.05 = 5%)\n",
    "MIN_UNITS = 1                # minimale Anzahl Einheiten zu handeln\n",
    "TRANSACTION_COST_PER_UNIT = 0.0  # fixe Transaktionskosten pro Einheit (EUR)\n",
    "STRATEGY = 'zscore'          # 'zscore' oder 'sma'\n",
    "\n",
    "# Z-Score (Mean Reversion) Parameter\n",
    "ROLL_WINDOW = 96    # Rolling window in periods (96 ~ 1 Tag bei 15min-Auflösung)\n",
    "Z_ENTRY = -1.0\n",
    "Z_EXIT = 0.0\n",
    "\n",
    "# SMA Momentum Parameter (alternativ)\n",
    "SMA_SHORT = 12\n",
    "SMA_LONG = 48\n",
    "\n",
    "# --- Lade CSV ---\n",
    "files = list(Path('.').rglob(CSV_FILENAME))\n",
    "if not files:\n",
    "    files = list(Path('..').rglob(CSV_FILENAME))\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"Datei {CSV_FILENAME} nicht gefunden. Bitte stelle sicher, dass sie im Workspace vorhanden ist.\")\n",
    "file_path = files[0]\n",
    "print(f\"Lade Datei: {file_path}\")\n",
    "\n",
    "# CSV mit Semikolon-Trennzeichen lesen\n",
    "df = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Datetime-Spalte ist bereits vorhanden und korrekt benannt\n",
    "if 'datetime' not in df.columns:\n",
    "    raise ValueError('Die CSV muss eine Spalte namens \"datetime\" enthalten.')\n",
    "\n",
    "# Konvertiere datetime zu Pandas datetime\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Preis-Spalte (value) ist bereits vorhanden\n",
    "if 'value' not in df.columns:\n",
    "    raise ValueError('Die CSV muss eine Spalte namens \"value\" enthalten.')\n",
    "\n",
    "df = df[['datetime', 'value']].rename(columns={'value': 'price'})\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "df = df.dropna(subset=['price']).sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "print(f\"Eingelesene Daten: {len(df)} Zeilen von {df['datetime'].min()} bis {df['datetime'].max()}\")\n",
    "\n",
    "# Indikatoren berechnen\n",
    "if STRATEGY == 'zscore':\n",
    "    df['rolling_mean'] = df['price'].rolling(window=ROLL_WINDOW, min_periods=20).mean()\n",
    "    df['rolling_std'] = df['price'].rolling(window=ROLL_WINDOW, min_periods=20).std()\n",
    "    df['zscore'] = (df['price'] - df['rolling_mean']) / df['rolling_std']\n",
    "elif STRATEGY == 'sma':\n",
    "    df['sma_short'] = df['price'].rolling(SMA_SHORT, min_periods=1).mean()\n",
    "    df['sma_long'] = df['price'].rolling(SMA_LONG, min_periods=1).mean()\n",
    "else:\n",
    "    raise ValueError('Unbekannte Strategie')\n",
    "\n",
    "# Backtest-Simulation\n",
    "cash = START_CAPITAL\n",
    "position = 0.0\n",
    "entry_price = None\n",
    "trades = []\n",
    "equity_curve = []\n",
    "\n",
    "# Hilfsfunktion zur Bestimmung der Einheiten basierend auf Risiko\n",
    "def units_from_risk(equity, price, risk_per_trade, transaction_cost_per_unit=0.0):\n",
    "    # Vereinfacht: wir erlauben, dass die gesamte 'risk_per_trade' des Equity in Position investiert wird\n",
    "    notional = equity * risk_per_trade\n",
    "    units = math.floor(notional / (price + transaction_cost_per_unit))\n",
    "    return max(int(units), 0)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    price = row['price']\n",
    "    t = row['datetime']\n",
    "\n",
    "    # mark-to-market equity\n",
    "    equity = cash + position * price\n",
    "    equity_curve.append({'datetime': t, 'equity': equity})\n",
    "\n",
    "    # Signale\n",
    "    if STRATEGY == 'zscore':\n",
    "        z = row.get('zscore', np.nan)\n",
    "        if not np.isfinite(z):\n",
    "            continue\n",
    "        # Entry long when z <= Z_ENTRY and no position\n",
    "        if z <= Z_ENTRY and position == 0:\n",
    "            units = units_from_risk(equity, price, RISK_PER_TRADE, TRANSACTION_COST_PER_UNIT)\n",
    "            if units < MIN_UNITS:\n",
    "                units = MIN_UNITS\n",
    "            cost = units * price + units * TRANSACTION_COST_PER_UNIT\n",
    "            if cash >= cost and units > 0:\n",
    "                cash -= cost\n",
    "                position += units\n",
    "                trades.append({'entry_time': t, 'entry_price': price, 'units': units, 'exit_time': None, 'exit_price': None, 'profit': None})\n",
    "        # Exit when z >= Z_EXIT\n",
    "        elif z >= Z_EXIT and position > 0:\n",
    "            units = position\n",
    "            proceeds = units * price - units * TRANSACTION_COST_PER_UNIT\n",
    "            cash += proceeds\n",
    "            if trades and trades[-1]['exit_time'] is None:\n",
    "                trades[-1]['exit_time'] = t\n",
    "                trades[-1]['exit_price'] = price\n",
    "                trades[-1]['profit'] = (price - trades[-1]['entry_price']) * trades[-1]['units'] - trades[-1]['units'] * TRANSACTION_COST_PER_UNIT * 2\n",
    "            position = 0\n",
    "    elif STRATEGY == 'sma':\n",
    "        sma_s = row.get('sma_short')\n",
    "        sma_l = row.get('sma_long')\n",
    "        if np.isnan(sma_s) or np.isnan(sma_l):\n",
    "            continue\n",
    "        # Crossover logic\n",
    "        prev = df.iloc[idx-1] if idx>0 else None\n",
    "        prev_s = prev['sma_short'] if prev is not None else np.nan\n",
    "        prev_l = prev['sma_long'] if prev is not None else np.nan\n",
    "        # Golden cross -> buy\n",
    "        if prev_s <= prev_l and sma_s > sma_l and position == 0:\n",
    "            units = units_from_risk(equity, price, RISK_PER_TRADE, TRANSACTION_COST_PER_UNIT)\n",
    "            if units < MIN_UNITS:\n",
    "                units = MIN_UNITS\n",
    "            cost = units * price + units * TRANSACTION_COST_PER_UNIT\n",
    "            if cash >= cost and units > 0:\n",
    "                cash -= cost\n",
    "                position += units\n",
    "                trades.append({'entry_time': t, 'entry_price': price, 'units': units, 'exit_time': None, 'exit_price': None, 'profit': None})\n",
    "        # Death cross -> sell\n",
    "        if prev_s >= prev_l and sma_s < sma_l and position > 0:\n",
    "            units = position\n",
    "            proceeds = units * price - units * TRANSACTION_COST_PER_UNIT\n",
    "            cash += proceeds\n",
    "            if trades and trades[-1]['exit_time'] is None:\n",
    "                trades[-1]['exit_time'] = t\n",
    "                trades[-1]['exit_price'] = price\n",
    "                trades[-1]['profit'] = (price - trades[-1]['entry_price']) * trades[-1]['units'] - trades[-1]['units'] * TRANSACTION_COST_PER_UNIT * 2\n",
    "            position = 0\n",
    "\n",
    "# Liquidation am Ende\n",
    "if position > 0:\n",
    "    last_price = df['price'].iloc[-1]\n",
    "    cash += position * last_price - position * TRANSACTION_COST_PER_UNIT\n",
    "    if trades and trades[-1]['exit_time'] is None:\n",
    "        trades[-1]['exit_time'] = df['datetime'].iloc[-1]\n",
    "        trades[-1]['exit_price'] = last_price\n",
    "        trades[-1]['profit'] = (last_price - trades[-1]['entry_price']) * trades[-1]['units'] - trades[-1]['units'] * TRANSACTION_COST_PER_UNIT * 2\n",
    "    position = 0\n",
    "\n",
    "final_equity = cash\n",
    "pnl = final_equity - START_CAPITAL\n",
    "\n",
    "# Equity DataFrame\n",
    "equity_df = pd.DataFrame(equity_curve).drop_duplicates(subset='datetime').reset_index(drop=True)\n",
    "\n",
    "# Performance Kennzahlen\n",
    "# Jahreslänge approximieren anhand Zeitspanne\n",
    "days = (equity_df['datetime'].iloc[-1] - equity_df['datetime'].iloc[0]).total_seconds() / (3600*24)\n",
    "years = max(days / 365.25, 1/365.25)\n",
    "\n",
    "cagr = (final_equity / START_CAPITAL) ** (1/years) - 1\n",
    "\n",
    "# Resample equity to daily for Sharpe\n",
    "equity_daily = equity_df.set_index('datetime').resample('1D').last().ffill()\n",
    "returns = equity_daily['equity'].pct_change().dropna()\n",
    "\n",
    "if len(returns) > 1:\n",
    "    mean_ret = returns.mean()\n",
    "    std_ret = returns.std()\n",
    "    # annualize daily returns\n",
    "    sharpe = (mean_ret / std_ret) * math.sqrt(252) if std_ret > 0 else np.nan\n",
    "else:\n",
    "    sharpe = np.nan\n",
    "\n",
    "# Max Drawdown\n",
    "running_max = equity_df['equity'].cummax()\n",
    "drawdown = (equity_df['equity'] - running_max) / running_max\n",
    "max_dd = drawdown.min()\n",
    "\n",
    "# Trades DataFrame\n",
    "trades_df = pd.DataFrame(trades)\n",
    "\n",
    "# Ausgabe\n",
    "print('\\nBacktest Ergebnis:')\n",
    "print(f'Strategie: {STRATEGY}')\n",
    "print(f'Startkapital: {START_CAPITAL:,.2f} EUR')\n",
    "print(f'Endkapital: {final_equity:,.2f} EUR')\n",
    "print(f'Gewinn/Verlust: {pnl:,.2f} EUR ({pnl/START_CAPITAL*100:,.2f} %)')\n",
    "print(f'CAGR: {cagr*100:.2f} %')\n",
    "print(f'Sharpe (daily returns): {sharpe:.2f}')\n",
    "print(f'Max Drawdown: {max_dd*100:.2f} %')\n",
    "print(f'Anzahl Trades: {len(trades_df)}')\n",
    "\n",
    "# Plots: Equity und Drawdown\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=equity_df['datetime'], y=equity_df['equity'], mode='lines', name='Equity'))\n",
    "fig.update_layout(title='Equity Curve', yaxis_title='Equity (EUR)', xaxis_title='Datum')\n",
    "fig.show()\n",
    "\n",
    "fig2 = go.Figure()\n",
    "fig2.add_trace(go.Scatter(x=equity_df['datetime'], y=drawdown, mode='lines', name='Drawdown'))\n",
    "fig2.update_layout(title='Drawdown', yaxis_title='Drawdown', xaxis_title='Datum')\n",
    "fig2.show()\n",
    "\n",
    "# Speichern\n",
    "trades_out = 'trades_backtest_strommarkt.csv'\n",
    "equity_out = 'equity_curve_backtest.csv'\n",
    "trades_df.to_csv(trades_out, index=False)\n",
    "equity_df.to_csv(equity_out, index=False)\n",
    "print(f'Trades gespeichert in: {trades_out}')\n",
    "print(f'Equity-Kurve gespeichert in: {equity_out}')\n",
    "\n",
    "# Kurze Vorschau der Trades\n",
    "if not trades_df.empty:\n",
    "    display(trades_df.head(20))\n",
    "else:\n",
    "    print('Keine Trades ausgeführt.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
